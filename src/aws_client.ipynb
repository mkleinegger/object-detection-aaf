{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establish Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_access_key_id=\"ASIARQHDHGQDEUEKTCO2\"\n",
    "aws_secret_access_key=\"A+um1/8F55q1IzXuyQ+Jc4htXFGaWlRuMZvDzq9N\"\n",
    "aws_session_token=\"IQoJb3JpZ2luX2VjEJH//////////wEaCXVzLXdlc3QtMiJHMEUCIQDTBd20v76ZnJEheBFF2NR7NSA1GRuhU50NSv0zpyIgFQIgDroRuRp5RvXSkv1BiwyhHoZAWU8uCzZghVFtgeIcdkUquAIIShABGgwxMDM1NTU3NDA2NzgiDEJIdrKqj+J5H5jquSqVAudUtaaHAUmvktHak1uG0fn2CXzfhJhPz6qa8aM+vlJBGMNHnsfF6gaWks6f2poondFl1wEXOqhhKRqGXSwtmCeEV1Ko9e25F8DSHzwwe3IUTfEDj2/C4F//tOjGBrsqCXXFqPmOrbdQKl3gxyNdukapNrdrLeOE6vqzr+9D5GbqgpyVznysSOf7ZDFlEzaOpc0UMgeICGV09yClx4CVBP4XOzx8NMKmxISOxf/Pol/iHYDnFYmgMD46Uhfab/f6eUqLU7vI7Kp2eQw3BEroDBVwxrpc47CWrrmjCDicDDU8QBNQPNgoXD02WGM8lNYKwbS57E+eXG94wKPtyXDDtnE1zRoyDSF65hMPkuHl9ChSHoOi4UgwxZyGtAY6nQFaUNmMquYg0z4BQ/bwA4wZlLiN0TRzXbb+JtokfBuIU/kpGVItplSy5ga5iaryksDbuFZ0VIihSk9QjFsv//9ni3jEmtudtSDbckUQFYzAsdsrq2+wicAgKvyd4i/8XMZyCZ+7tnROTLihxVCXrFsxLHzykOzyEpeY5J9gA3bVLSfqTo3MxCbaARKFGaq6u9hRSHYqjYavPSclK9LD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "s3 = boto3.client( #.resource\n",
    "    's3',\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    "    aws_session_token= aws_session_token\n",
    ")\n",
    "#for bucket in s3.buckets.all():\n",
    "#    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    :param file_name: File to upload\n",
    "    :param bucket: Bucket to upload to\n",
    "    :param object_name: S3 object name. If not specified then file_name is used\n",
    "    :return: True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = os.path.basename(file_name)\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../input_data/000000000016.jpg\"\n",
    "BUCKET = \"e12239877-uploaded-images\"\n",
    "with open(PATH, \"rb\") as f:\n",
    "    s3.upload_fileobj(f, BUCKET, \"test.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000000016.jpg\n",
      "000000000057.jpg\n",
      "000000000019.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "#input_folder = \"../input_data/\"\n",
    "input_folder = \"../test_input/\"\n",
    "BUCKET = \"e12239877-uploaded-images\"\n",
    "transfer_time = {}\n",
    "\n",
    "for file_name in os.listdir(input_folder):\n",
    "    path_to_img = input_folder + file_name\n",
    "    print(file_name)\n",
    "    with open(path_to_img, \"rb\") as f:\n",
    "        start = time.time()\n",
    "        s3.upload_fileobj(f, BUCKET, file_name)\n",
    "        end = time.time()\n",
    "        transfer_time[file_name] = end-start\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average Transfer Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42s\n"
     ]
    }
   ],
   "source": [
    "avg_transfer_time = sum(transfer_time.values()) / len(transfer_time.values())\n",
    "print(f\"{avg_transfer_time:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average Inference Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def download_dynamodb_data():\n",
    "    dynamodb_client = boto3.client(\"dynamodb\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        aws_session_token= aws_session_token,\n",
    "        region_name = 'us-east-1')\n",
    "\n",
    "    # Specify the table name\n",
    "    table_name = 'e12239877-detected-objects'\n",
    "    items = []\n",
    "    # Initial scan request\n",
    "    response = dynamodb_client.scan(TableName=table_name)\n",
    "    items.extend(response.get('Items', []))\n",
    "\n",
    "    # Convert DynamoDB items to a more readable format\n",
    "    formatted_items = []\n",
    "    for item in items:\n",
    "        formatted_item = {}\n",
    "        for key, value in item.items():\n",
    "            formatted_item[key] = list(value.values())[0]\n",
    "        formatted_items.append(formatted_item)\n",
    "\n",
    "    # Save items to a local JSON file\n",
    "    with open('../evaluation/dynamodb_data.json', 'w') as outfile:\n",
    "        json.dump(formatted_items, outfile, indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.57s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# wait for lambda function\n",
    "#time.sleep(20)\n",
    "\n",
    "# load dynamo_data\n",
    "download_dynamodb_data()\n",
    "\n",
    "df = pd.read_json(\"../evaluation/dynamodb_data.json\")\n",
    "avg_inference_time = df[\"Inference-Time\"].mean()\n",
    "print(f\"{avg_inference_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dic-ex3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
